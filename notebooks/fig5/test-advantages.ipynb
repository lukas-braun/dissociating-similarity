{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0dcf3f6-53ec-42c2-882a-51aedab3048a",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfd24b4-a56a-41c6-aa5f-4bc7e1f3ad34",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from functools import partial\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import equinox as eqx\n",
    "import treescope\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(\"../style.mplstyle\")\n",
    "colors = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb85080-6332-41be-b2e6-811b2dddc742",
   "metadata": {},
   "source": [
    "### Load MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fafb29-59e0-457a-8da5-3931b15fe490",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dissociation.fig4.mnist import mnist_data\n",
    "\n",
    "_, _, mnist_test_images, mnist_test_labels = mnist_data()\n",
    "\n",
    "batch_size = 1024\n",
    "mnist_test_image_batch = mnist_test_images[:batch_size]\n",
    "mnist_test_label_batch = mnist_test_labels[:batch_size]\n",
    "\n",
    "# Sort by label\n",
    "idx = jnp.argsort(mnist_test_label_batch.argmax(-1))\n",
    "mnist_test_image_batch = mnist_test_image_batch[idx]\n",
    "mnist_test_label_batch = mnist_test_label_batch[idx]\n",
    "\n",
    "treescope.render_array(\n",
    "    mnist_test_image_batch.reshape(-1, 28, 28)[:20],\n",
    "    pixels_per_cell=1,\n",
    "    columns=[2, 0],\n",
    "    axis_labels={0: \"input example\", 1: \"input dimension\", 2: \"input dimension\"},\n",
    "    vmax=1,\n",
    "    vmin=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83094b9c-e02e-4a71-9f36-3024358de490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_null_space_dimension(dataset):\n",
    "    \"\"\"Calculate the dimensionality of the null space of a dataset using JAX.\"\"\"\n",
    "    if len(dataset.shape) > 2:\n",
    "        flattened_dataset = dataset.reshape(dataset.shape[0], -1)\n",
    "    else:\n",
    "        flattened_dataset = dataset\n",
    "\n",
    "    num_samples, num_features = flattened_dataset.shape\n",
    "\n",
    "    rank = jnp.linalg.matrix_rank(flattened_dataset)\n",
    "    null_space_dim = num_features - rank\n",
    "\n",
    "    return null_space_dim, rank, num_features\n",
    "\n",
    "\n",
    "def get_null_basis(dataset, rtol=None):\n",
    "    \"\"\"Get the basis vectors for the null space using JAX SVD.\"\"\"\n",
    "    if len(dataset.shape) > 2:\n",
    "        flattened_dataset = dataset.reshape(dataset.shape[0], -1)\n",
    "    else:\n",
    "        flattened_dataset = dataset\n",
    "\n",
    "    U, S, Vt = jnp.linalg.svd(flattened_dataset, full_matrices=True)\n",
    "\n",
    "    # Same as `jnp.linalg.matrix_rank`.\n",
    "    if rtol is None:\n",
    "        rtol = (\n",
    "            S.max(-1)\n",
    "            * jnp.max(jnp.array(flattened_dataset.shape[-2:])).astype(S.dtype)\n",
    "            * jnp.finfo(S.dtype).eps\n",
    "        )\n",
    "    rtol = jnp.expand_dims(rtol, jnp.ndim(rtol))\n",
    "\n",
    "    null_indices = S <= rtol\n",
    "    null_space_vectors = Vt[null_indices]\n",
    "\n",
    "    if len(dataset.shape) > 2:\n",
    "        original_shape = dataset.shape[1:]\n",
    "        null_space_basis = null_space_vectors.reshape(-1, *original_shape)\n",
    "    else:\n",
    "        null_space_basis = null_space_vectors\n",
    "\n",
    "    return null_space_basis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1a5628-4cf5-4077-82bd-d59f6b11a6ac",
   "metadata": {},
   "source": [
    "### Train model on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0101d28b-8b92-4a05-be48-d65638cba440",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from dissociation.fig4.mnist import train_mnist\n",
    "\n",
    "num_seeds = 2\n",
    "mnist_model = train_mnist(num_seeds=num_seeds, num_epochs=0)  # 30)\n",
    "mnist_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016bdc3e-97c1-4f49-b8c3-78cd6467505d",
   "metadata": {},
   "source": [
    "### Manipulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc2e6f6-331c-492b-a10f-1e96e8b993b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dissociation.fig4.bmap import bmap\n",
    "\n",
    "num_samples, num_features = mnist_test_images.shape\n",
    "max_rank = min(num_samples, num_features)\n",
    "rank = jnp.linalg.matrix_rank(mnist_test_images)\n",
    "null_space_dim = max_rank - rank\n",
    "\n",
    "null_basis = get_null_basis(mnist_test_images)\n",
    "assert null_basis.shape[0] == null_space_dim\n",
    "print(f\"Null space basis shape: {null_basis.shape}\")\n",
    "\n",
    "\n",
    "@partial(bmap, in_axes=(eqx.if_array(0), None, 0))\n",
    "def input_null_space_manipulation(model, noise_scale, key):\n",
    "    W1 = model.layers[0].weight\n",
    "    hidden_dim, _ = W1.shape\n",
    "    null_dim, _ = null_basis.shape\n",
    "\n",
    "    noise_coeffs = jax.random.normal(key, (hidden_dim, null_dim)) * noise_scale\n",
    "    null_space_noise = jnp.dot(noise_coeffs, null_basis)\n",
    "\n",
    "    new_W1 = W1 + null_space_noise\n",
    "    new_model = eqx.tree_at(lambda x: x.layers[0].weight, model, new_W1)\n",
    "\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2465d961-2972-4d2e-a8bf-2ce8c3585b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dissociation.fig4.expand import scale_neurons\n",
    "from dissociation.fig4.expand import duplicate_neurons\n",
    "from dissociation.fig4.expand import add_random_zero_neurons\n",
    "\n",
    "\n",
    "@partial(bmap, in_axes=(eqx.if_array(0), None))\n",
    "def scale_manipulation(model, scale_factor):\n",
    "    W2 = model.layers[1].weight\n",
    "    W3 = model.layers[2].weight\n",
    "    new_W2, new_W3 = scale_neurons(w_in=W2, w_out=W3, scale_factor=scale_factor)\n",
    "    new_model = eqx.tree_at(lambda x: x.layers[1].weight, model, new_W2)\n",
    "    new_model = eqx.tree_at(lambda x: x.layers[2].weight, new_model, new_W3)\n",
    "    return new_model\n",
    "\n",
    "\n",
    "@partial(bmap, in_axes=(eqx.if_array(0), None))\n",
    "def duplicate_type_manipulation(model, duplicate_multiplier):\n",
    "    W2 = model.layers[1].weight\n",
    "    W3 = model.layers[2].weight\n",
    "    new_W2, new_W3 = duplicate_neurons(\n",
    "        w_in=W2, w_out=W3, duplicate_multiplier=duplicate_multiplier\n",
    "    )\n",
    "    new_model = eqx.tree_at(lambda x: x.layers[1].weight, model, new_W2)\n",
    "    new_model = eqx.tree_at(lambda x: x.layers[2].weight, new_model, new_W3)\n",
    "    return new_model\n",
    "\n",
    "\n",
    "@partial(bmap, in_axes=(eqx.if_array(0), None, 0))\n",
    "def zero_type_manipulation(model, num_units, key):\n",
    "    W2 = model.layers[1].weight\n",
    "    W3 = model.layers[2].weight\n",
    "    new_W2, new_W3 = add_random_zero_neurons(\n",
    "        w_in=W2, w_out=W3, num_zero_groups=num_units, neurons_per_group=1, key=key\n",
    "    )\n",
    "    new_model = eqx.tree_at(lambda x: x.layers[1].weight, model, new_W2)\n",
    "    new_model = eqx.tree_at(lambda x: x.layers[2].weight, new_model, new_W3)\n",
    "    return new_model\n",
    "\n",
    "\n",
    "@partial(bmap, in_axes=(None, 0, None))\n",
    "@partial(bmap, in_axes=(eqx.if_array(0), None, 0))\n",
    "def parameter_noise_manipulation(model, noise_scale, key):\n",
    "    W1 = model.layers[0].weight\n",
    "    W2 = model.layers[1].weight\n",
    "    W3 = model.layers[2].weight\n",
    "\n",
    "    key = jax.random.split(key, 3)\n",
    "    new_W1 = W1 + noise_scale * jax.random.normal(key[0], W1.shape)\n",
    "    new_W2 = W2 + noise_scale * jax.random.normal(key[1], W2.shape)\n",
    "    new_W3 = W3 + noise_scale * jax.random.normal(key[2], W3.shape)\n",
    "\n",
    "    new_model = eqx.tree_at(lambda x: x.layers[0].weight, model, new_W1)\n",
    "    new_model = eqx.tree_at(lambda x: x.layers[1].weight, new_model, new_W2)\n",
    "    new_model = eqx.tree_at(lambda x: x.layers[2].weight, new_model, new_W3)\n",
    "    return new_model\n",
    "\n",
    "\n",
    "def accuracy(pred_y, y):\n",
    "    target_class = jnp.argmax(y, axis=1)\n",
    "    predicted_class = jnp.argmax(pred_y, axis=1)\n",
    "    return jnp.mean(predicted_class == target_class)\n",
    "\n",
    "\n",
    "@partial(bmap, in_axes=(eqx.if_array(0), None, None))\n",
    "@partial(bmap, in_axes=(None, 0, None))\n",
    "def gen_error_input_noise(model, noise_scale, key):\n",
    "    def _forward(x):\n",
    "        return model(x)\n",
    "\n",
    "    pred_y = jax.lax.map(\n",
    "        _forward,\n",
    "        mnist_test_images\n",
    "        + noise_scale * jax.random.normal(key, mnist_test_images.shape),\n",
    "        batch_size=16,\n",
    "    )\n",
    "\n",
    "    test_error = 1 - accuracy(pred_y, mnist_test_labels)\n",
    "    return test_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14619d8-7528-4cc9-9f90-f09cc39efb32",
   "metadata": {},
   "source": [
    "### Test input noise robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56500f9d-592e-479f-8301-30e981b9c317",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(37)\n",
    "data_key, zero_key = jax.random.split(key)\n",
    "noise_scales = jnp.logspace(-1, 1, num=40)\n",
    "\n",
    "task_optimized_model_input_robustness = gen_error_input_noise(\n",
    "    mnist_model, noise_scales, data_key\n",
    ")\n",
    "task_optimized_model_input_robustness.mean(0)\n",
    "\n",
    "duplicated_model_input_robustness = gen_error_input_noise(\n",
    "    scale_manipulation(mnist_model, 20), noise_scales, data_key\n",
    ")\n",
    "duplicated_model_input_robustness.mean(0)\n",
    "\n",
    "scaled_model_input_robustness = gen_error_input_noise(\n",
    "    duplicate_type_manipulation(mnist_model, 1 + 1), noise_scales, data_key\n",
    ")\n",
    "scaled_model_input_robustness.mean(0)\n",
    "\n",
    "zeroed_model_input_robustness = gen_error_input_noise(\n",
    "    zero_type_manipulation(\n",
    "        mnist_model, 1 * 1024, jax.random.split(zero_key, num_seeds)\n",
    "    ),\n",
    "    noise_scales,\n",
    "    data_key,\n",
    ")\n",
    "zeroed_model_input_robustness.mean(0)\n",
    "\n",
    "kernel_noise_model_input_robustness = gen_error_input_noise(\n",
    "    input_null_space_manipulation(\n",
    "        mnist_model, 1e-1, jax.random.split(zero_key, num_seeds)\n",
    "    ),\n",
    "    noise_scales,\n",
    "    data_key,\n",
    ")\n",
    "kernel_noise_model_input_robustness.mean(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b85710-0b8d-420d-b23b-0331935ad1bf",
   "metadata": {},
   "source": [
    "### Test parameter noise robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8294260-a0d9-4c45-b424-119c1e65c8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@partial(bmap, in_axes=(eqx.if_array(0),))\n",
    "def gen_error(model):\n",
    "    def _forward(x):\n",
    "        return model(x)\n",
    "\n",
    "    pred_y = jax.lax.map(\n",
    "        _forward,\n",
    "        mnist_test_images,\n",
    "        batch_size=16,\n",
    "    )\n",
    "\n",
    "    test_error = 1 - accuracy(pred_y, mnist_test_labels)\n",
    "    return test_error\n",
    "\n",
    "\n",
    "key = jax.random.PRNGKey(37)\n",
    "noise_scales = jnp.logspace(-4, 0, num=40)\n",
    "\n",
    "task_optimized_model_robustness = eqx.filter_vmap(\n",
    "    gen_error, in_axes=(eqx.if_array(0),)\n",
    ")(\n",
    "    parameter_noise_manipulation(\n",
    "        mnist_model, noise_scales, jax.random.split(key, num_seeds)\n",
    "    )\n",
    ")\n",
    "\n",
    "duplicated_model_robustness = eqx.filter_vmap(gen_error, in_axes=(eqx.if_array(0),))(\n",
    "    parameter_noise_manipulation(\n",
    "        duplicate_type_manipulation(mnist_model, 1 + 1),\n",
    "        noise_scales,\n",
    "        jax.random.split(key, num_seeds),\n",
    "    )\n",
    ")\n",
    "\n",
    "scaled_model_robustness = eqx.filter_vmap(gen_error, in_axes=(eqx.if_array(0),))(\n",
    "    parameter_noise_manipulation(\n",
    "        scale_manipulation(mnist_model, 20),\n",
    "        noise_scales,\n",
    "        jax.random.split(key, num_seeds),\n",
    "    )\n",
    ")\n",
    "\n",
    "zeroed_model_robustness = eqx.filter_vmap(gen_error, in_axes=(eqx.if_array(0),))(\n",
    "    parameter_noise_manipulation(\n",
    "        zero_type_manipulation(mnist_model, 1 * 1024, jax.random.split(key, num_seeds)),\n",
    "        noise_scales,\n",
    "        jax.random.split(key, num_seeds),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76080217-483a-42a1-88a9-5be1496e69a5",
   "metadata": {},
   "source": [
    "### Plot noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d177424e-d807-4948-b4a7-3abd003f9897",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(1.8 * 1.8, 1.6))\n",
    "axs = axs.flatten()\n",
    "\n",
    "# First subplot - input noise robustness\n",
    "ax = axs[0]\n",
    "\n",
    "# Task optimized model\n",
    "mean_task = np.mean(task_optimized_model_input_robustness, axis=0)\n",
    "std_task = np.std(task_optimized_model_input_robustness, axis=0)\n",
    "ax.plot(noise_scales, mean_task, linewidth=1, label=\"trained\")\n",
    "ax.fill_between(noise_scales, mean_task - std_task, mean_task + std_task, alpha=0.2)\n",
    "\n",
    "# Kernel perturbed model\n",
    "mean_kernel = np.mean(kernel_noise_model_input_robustness, axis=0)\n",
    "std_kernel = np.std(kernel_noise_model_input_robustness, axis=0)\n",
    "ax.plot(noise_scales, mean_kernel, linewidth=1, label=\"input null-perturbed\")\n",
    "ax.fill_between(\n",
    "    noise_scales, mean_kernel - std_kernel, mean_kernel + std_kernel, alpha=0.2\n",
    ")\n",
    "\n",
    "# # Duplicated model\n",
    "# mean_dup = np.mean(duplicated_model_input_robustness, axis=0)\n",
    "# std_dup = np.std(duplicated_model_input_robustness, axis=0)\n",
    "# ax.plot(noise_scales, mean_dup, linewidth=1, label=\"duplicate\")\n",
    "# ax.fill_between(noise_scales, mean_dup - std_dup, mean_dup + std_dup, alpha=0.2)\n",
    "\n",
    "# # Scaled model\n",
    "# mean_scaled = np.mean(scaled_model_input_robustness, axis=0)\n",
    "# std_scaled = np.std(scaled_model_input_robustness, axis=0)\n",
    "# ax.plot(noise_scales, mean_scaled, linewidth=1, label=\"scaled\")\n",
    "# ax.fill_between(\n",
    "#     noise_scales, mean_scaled - std_scaled, mean_scaled + std_scaled, alpha=0.2\n",
    "# )\n",
    "\n",
    "# # Zeroed model\n",
    "# mean_zeroed = np.mean(zeroed_model_input_robustness, axis=0)\n",
    "# std_zeroed = np.std(zeroed_model_input_robustness, axis=0)\n",
    "# ax.plot(noise_scales, mean_zeroed, linewidth=1, label=\"nuisance\")\n",
    "# ax.fill_between(\n",
    "#     noise_scales, mean_zeroed - std_zeroed, mean_zeroed + std_zeroed, alpha=0.2\n",
    "# )\n",
    "\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xlabel(\"noise scale (log)\", labelpad=2)\n",
    "ax.set_ylabel(\"test error (log)\", labelpad=2)\n",
    "\n",
    "# Remove top and right spines\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "ax.legend(handlelength=0.5, fontsize=5)\n",
    "ax.set_xlim(left=2e-3)\n",
    "ax.set_ylim(bottom=1e-2)\n",
    "ax.tick_params(axis=\"both\", which=\"major\", labelsize=7)\n",
    "\n",
    "# Second subplot - parameter noise robustness\n",
    "ax = axs[1]\n",
    "\n",
    "# Task optimized model\n",
    "mean_task = np.mean(task_optimized_model_robustness, axis=1)\n",
    "std_task = np.std(task_optimized_model_robustness, axis=1)\n",
    "ax.plot(noise_scales, mean_task, linewidth=1, label=\"trained\")\n",
    "ax.fill_between(noise_scales, mean_task - std_task, mean_task + std_task, alpha=0.2)\n",
    "\n",
    "# Duplicated model\n",
    "mean_dup = np.mean(duplicated_model_robustness, axis=1)\n",
    "std_dup = np.std(duplicated_model_robustness, axis=1)\n",
    "ax.plot(noise_scales, mean_dup, linewidth=1, label=\"duplicate\")\n",
    "ax.fill_between(noise_scales, mean_dup - std_dup, mean_dup + std_dup, alpha=0.2)\n",
    "\n",
    "# Scaled model\n",
    "mean_scaled = np.mean(scaled_model_robustness, axis=1)\n",
    "std_scaled = np.std(scaled_model_robustness, axis=1)\n",
    "ax.plot(noise_scales, mean_scaled, linewidth=1, label=\"scaled\")\n",
    "ax.fill_between(\n",
    "    noise_scales, mean_scaled - std_scaled, mean_scaled + std_scaled, alpha=0.2\n",
    ")\n",
    "\n",
    "# Zeroed model\n",
    "mean_zeroed = np.mean(zeroed_model_robustness, axis=1)\n",
    "std_zeroed = np.std(zeroed_model_robustness, axis=1)\n",
    "ax.plot(noise_scales, mean_zeroed, linewidth=1, label=\"nuisance\")\n",
    "ax.fill_between(\n",
    "    noise_scales, mean_zeroed - std_zeroed, mean_zeroed + std_zeroed, alpha=0.2\n",
    ")\n",
    "\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xlabel(\"noise scale (log)\", labelpad=2)\n",
    "ax.set_ylabel(\"test error (log)\", labelpad=2)\n",
    "\n",
    "# Remove top and right spines\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "ax.legend(handlelength=0.5, fontsize=5)\n",
    "ax.set_xlim(left=2e-3)\n",
    "ax.set_ylim(bottom=1e-2)\n",
    "ax.tick_params(axis=\"both\", which=\"major\", labelsize=7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"noise-robustness.pdf\", format=\"pdf\", bbox_inches=\"tight\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae6d8da-3c92-4ace-b8fc-66257af532c7",
   "metadata": {},
   "source": [
    "### Transferability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649d67e4-9f79-4d8a-b835-702106b54fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_layer_preacts(model, inputs):\n",
    "    return model.layers[0](inputs)\n",
    "\n",
    "\n",
    "def get_first_layer_postacts(model, inputs):\n",
    "    return model.activation(get_first_layer_preacts(model, inputs))\n",
    "\n",
    "\n",
    "def get_second_layer_preacts(model, inputs):\n",
    "    return model.layers[1](get_first_layer_postacts(model, inputs))\n",
    "\n",
    "\n",
    "@partial(jax.vmap, in_axes=(None, 0))\n",
    "def get_second_layer_postacts(model, inputs):\n",
    "    return model.activation(get_second_layer_preacts(model, inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae262f6-b26d-4ac5-8200-a976c4989d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rotated_dataset(images, key):\n",
    "    n = len(images)\n",
    "    assert n % 4 == 0\n",
    "    split_size = n // 4\n",
    "    partitions = jnp.split(images[: split_size * 4], 4)\n",
    "\n",
    "    rot_0 = partitions[0]  # no rotation\n",
    "    rot_90 = jnp.rot90(partitions[1], k=1, axes=(1, 2))\n",
    "    rot_180 = jnp.rot90(partitions[2], k=2, axes=(1, 2))\n",
    "    rot_270 = jnp.rot90(partitions[3], k=3, axes=(1, 2))\n",
    "\n",
    "    labels_0 = jnp.zeros(split_size, dtype=jnp.int32)\n",
    "    labels_90 = jnp.ones(split_size, dtype=jnp.int32)\n",
    "    labels_180 = jnp.full(split_size, 2, dtype=jnp.int32)\n",
    "    labels_270 = jnp.full(split_size, 3, dtype=jnp.int32)\n",
    "\n",
    "    all_images = jnp.concatenate([rot_0, rot_90, rot_180, rot_270])\n",
    "    all_labels = jnp.concatenate([labels_0, labels_90, labels_180, labels_270])\n",
    "\n",
    "    perm = jax.random.permutation(key, len(all_images))\n",
    "    shuffled_images = all_images[perm]\n",
    "    shuffled_labels = all_labels[perm]\n",
    "\n",
    "    return shuffled_images, shuffled_labels\n",
    "\n",
    "\n",
    "key = jax.random.PRNGKey(432)\n",
    "rotated_images, rotation_labels = create_rotated_dataset(\n",
    "    mnist_test_images.reshape(-1, 28, 28), key\n",
    ")\n",
    "rotated_images = rotated_images.reshape(-1, 28 * 28)\n",
    "print(rotation_labels[:10])\n",
    "rotation_labels = jax.nn.one_hot(rotation_labels, 4)\n",
    "treescope.render_array(\n",
    "    rotated_images.reshape(-1, 28, 28)[:10],\n",
    "    pixels_per_cell=1,\n",
    "    columns=[2, 0],\n",
    "    axis_labels={0: \"input example\", 1: \"input dimension\", 2: \"input dimension\"},\n",
    "    vmax=1,\n",
    "    vmin=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ddba57-3910-4051-a899-19a3ad11a4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_coarse_grained_dataset(images, key):\n",
    "    n = len(images)\n",
    "    assert n % 4 == 0\n",
    "    split_size = n // 4\n",
    "    partitions = jnp.split(images[: split_size * 4], 4)\n",
    "\n",
    "    rot_0 = partitions[0]  # no rotation\n",
    "    rot_90 = jnp.rot90(partitions[1], k=1, axes=(1, 2))\n",
    "    rot_180 = jnp.rot90(partitions[2], k=2, axes=(1, 2))\n",
    "    rot_270 = jnp.rot90(partitions[3], k=3, axes=(1, 2))\n",
    "\n",
    "    labels_0 = jnp.zeros(split_size, dtype=jnp.int32)\n",
    "    labels_90 = jnp.ones(split_size, dtype=jnp.int32)\n",
    "    labels_180 = jnp.full(split_size, 2, dtype=jnp.int32)\n",
    "    labels_270 = jnp.full(split_size, 3, dtype=jnp.int32)\n",
    "\n",
    "    all_images = jnp.concatenate([rot_0, rot_90, rot_180, rot_270])\n",
    "    all_labels = jnp.concatenate([labels_0, labels_90, labels_180, labels_270])\n",
    "\n",
    "    perm = jax.random.permutation(key, len(all_images))\n",
    "    shuffled_images = all_images[perm]\n",
    "    shuffled_labels = all_labels[perm]\n",
    "\n",
    "    return shuffled_images, shuffled_labels\n",
    "\n",
    "\n",
    "# re-classify 0 to 9 by their least prime factor (or 0 or 1)\n",
    "coarse_labels = {\n",
    "    \"0\": \"0\",\n",
    "    \"1\": \"1\",\n",
    "    \"2\": \"2\",  # prime\n",
    "    \"3\": \"3\",  # prime\n",
    "    \"4\": \"2\",\n",
    "    \"5\": \"5\",  # prime\n",
    "    \"6\": \"2\",\n",
    "    \"7\": \"7\",  # prime\n",
    "    \"8\": \"2\",\n",
    "    \"9\": \"3\",\n",
    "}\n",
    "\n",
    "key = jax.random.PRNGKey(432)\n",
    "rotated_images, rotation_labels = create_rotated_dataset(\n",
    "    mnist_test_images.reshape(-1, 28, 28), key\n",
    ")\n",
    "rotated_images = rotated_images.reshape(-1, 28 * 28)\n",
    "print(rotation_labels[:10])\n",
    "rotation_labels = jax.nn.one_hot(rotation_labels, 4)\n",
    "treescope.render_array(\n",
    "    rotated_images.reshape(-1, 28, 28)[:10],\n",
    "    pixels_per_cell=1,\n",
    "    columns=[2, 0],\n",
    "    axis_labels={0: \"input example\", 1: \"input dimension\", 2: \"input dimension\"},\n",
    "    vmax=1,\n",
    "    vmin=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6c4d6e-cca8-4fb9-8a40-3ba1c7ba4757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from logistic import crossval_softmax_predict\n",
    "\n",
    "\n",
    "def accuracy(pred_y, y):\n",
    "    target_class = jnp.argmax(y, axis=1)\n",
    "    predicted_class = jnp.argmax(pred_y, axis=1)\n",
    "    return 1 - jnp.mean(predicted_class == target_class)\n",
    "\n",
    "\n",
    "@partial(eqx.filter_vmap, in_axes=(eqx.if_array(0), None))\n",
    "def transfer_err(model, sample_proportion):\n",
    "    n = int(sample_proportion * len(rotated_images))\n",
    "    activations = get_second_layer_postacts(model, rotated_images[:n])\n",
    "    preds = crossval_softmax_predict(\n",
    "        activations, rotation_labels[:n], num_splits=10, key=None\n",
    "    )\n",
    "    return accuracy(preds, rotation_labels[:n])\n",
    "\n",
    "\n",
    "sample_proportions = tuple(map(float, np.arange(0.05, 1.05, 0.05)))\n",
    "sample_sizes = tuple(map(lambda x: int(x * 10000), sample_proportions))\n",
    "sample_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23d80e5-4333-4ec3-aec9-e2ef78d297b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_optimized_model_transferability = jnp.concatenate(\n",
    "    tuple(transfer_err(mnist_model, prop)[None, :] for prop in sample_proportions),\n",
    "    axis=0,\n",
    ")\n",
    "\n",
    "scaled_model_transferability = jnp.concatenate(\n",
    "    tuple(\n",
    "        transfer_err(scale_manipulation(mnist_model, 20), prop)[None, :]\n",
    "        for prop in sample_proportions\n",
    "    ),\n",
    "    axis=0,\n",
    ")\n",
    "\n",
    "duplicated_model_transferability = jnp.concatenate(\n",
    "    tuple(\n",
    "        transfer_err(duplicate_type_manipulation(mnist_model, 1.2), prop)[None, :]\n",
    "        for prop in sample_proportions\n",
    "    ),\n",
    "    axis=0,\n",
    ")\n",
    "\n",
    "zeroed_model_transferability = jnp.concatenate(\n",
    "    tuple(\n",
    "        transfer_err(\n",
    "            zero_type_manipulation(\n",
    "                mnist_model, 1 * 128, jax.random.split(key, num_seeds)\n",
    "            ),\n",
    "            prop,\n",
    "        )[None, :]\n",
    "        for prop in sample_proportions\n",
    "    ),\n",
    "    axis=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c31d9bc-2a0c-47d2-ae2a-0520b00df91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(1.6, 1.2))\n",
    "\n",
    "# Task optimized model\n",
    "mean_task = np.mean(task_optimized_model_transferability, axis=1)\n",
    "std_task = np.std(task_optimized_model_transferability, axis=1)\n",
    "plt.plot(sample_sizes, mean_task, linewidth=1, label=\"trained\")\n",
    "plt.fill_between(sample_sizes, mean_task - std_task, mean_task + std_task, alpha=0.2)\n",
    "\n",
    "# Duplicated model\n",
    "mean_dup = np.mean(duplicated_model_transferability, axis=1)\n",
    "std_dup = np.std(duplicated_model_transferability, axis=1)\n",
    "plt.plot(sample_sizes, mean_dup, linewidth=1, label=\"duplicate\")\n",
    "plt.fill_between(sample_sizes, mean_dup - std_dup, mean_dup + std_dup, alpha=0.2)\n",
    "\n",
    "# Scaled model\n",
    "mean_scaled = np.mean(scaled_model_transferability, axis=1)\n",
    "std_scaled = np.std(scaled_model_transferability, axis=1)\n",
    "plt.plot(sample_sizes, mean_scaled, linewidth=1, label=\"scaled\")\n",
    "plt.fill_between(\n",
    "    sample_sizes, mean_scaled - std_scaled, mean_scaled + std_scaled, alpha=0.2\n",
    ")\n",
    "\n",
    "# Zeroed model\n",
    "mean_zeroed = np.mean(zeroed_model_transferability, axis=1)\n",
    "std_zeroed = np.std(zeroed_model_transferability, axis=1)\n",
    "plt.plot(sample_sizes, mean_zeroed, linewidth=1, label=\"nuisance\")\n",
    "plt.fill_between(\n",
    "    sample_sizes, mean_zeroed - std_zeroed, mean_zeroed + std_zeroed, alpha=0.2\n",
    ")\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"sample budget (log)\")\n",
    "plt.ylabel(\"transfer error\")\n",
    "plt.legend(handlelength=0.5, fontsize=5, ncol=2)  # , bbox_to_anchor=(0.1, 0.65))\n",
    "\n",
    "plt.gca().spines[\"top\"].set_visible(False)\n",
    "plt.gca().spines[\"right\"].set_visible(False)\n",
    "\n",
    "plt.xlim(left=1000, right=10000)\n",
    "plt.ylim(bottom=0.0, top=1.0)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"transfer.pdf\", format=\"pdf\", bbox_inches=\"tight\", dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
